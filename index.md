---
title: Towards Trustworthy AI
feature_image: "https://picsum.photos/1300/400?image=222"
feature_text: |
  # Qiongkai Xu
  ### Research Fellow @ University of Melbourne
---

Dr. Qiongkai Xu is a research fellow on Security in NLP at the University of Melbourne (UoM) in Australia. Qiongkai's research primarily lies in among Privacy & Security, Natural Language Processing, Machine Learning and Data Mining. Recently, he is interested in ***auditing machine learning models***, such as 1) unvealing privacy and security issues in ML/NLP models and 2) evaluating ML/NLP models from various angles.

If you're as passionate about these research topics, I would love to hear your thoughts and ideas.
*Email: qiongkai.xu[at]unimelb.edu.au*


### Latest News
+ [Feb, 2023] I will be teaching **'Text Analytics for Business'** (BUSA90543) this winter semester.
+ [Feb, 2023] **'Security Challenges in Natural Language Processing Models'** is accepted to EMNLP 2023 (<span style="color:blue">Tutorial</span>). See you in Singapore!
+ [Jan, 2023] One paper **'On the Certification of Classifiers for Outperforming Human Annotators'** is accepted to ICLR'23 (<span style="color:red">spotlight, notable-top-25%</span>). If you would like to certify a 'superhuman' classifier, check our latest paper.
+ [Jan, 2023] Congrats to Yujin and Terry! One paper **'Training-Free Lexical Backdoor attacks on Language Models'** is accepted to WWW'23 (<span style="color:blue">oral, acceptance rate 19.2%</span>).
+ [Oct, 2022] Two papers are accepted to EMNLP main conference. Congrats to Zhuang and Xuanli!
+ [Sep, 2022] One paper is accepted to NeurIPS. Check our work on conditional watermarks for NLP APIs.
+ [Sep, 2022] I am honored to be invited to give a talk at TrustML YSS on **'Humanly Certifying Superhuman Classifiers'**.
+ [Aug, 2022] One paper **'Student Surpasses Teacher: Imitation Attack for Black-Box NLP APIs'** is accepted to COLING (<span style="color:blue">oral</span>).
<!-- + [Jun, 2022] I will join NLP Group @ University of Melbourne as a Research Fellow on Security in NLP. -->

### Recent and Selected Publications
+ [**On the Certification of Classifiers for Outperforming Human Annotators**](https://arxiv.org/abs/2109.07867), Qiongkai Xu, Christian Walder, Chenchen Xu
*<span style="color:gray">(Accepted to ICLR 2023, spotlight)</span>.*

+ [**Training-Free Lexical Backdoor Attacks on Language Models**](https://arxiv.org/abs/2302.04116), Yujin Huang, Terry Zhuo Yue, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen
*<span style="color:gray">(Accepted to WWW 2023)</span>.*

+ [**Variational Autoencoder with Disentanglement Priors for Low-Resource Task-Specific Natural Language Generation**](https://aclanthology.org/2022.emnlp-main.706), Zhuang Li, Lizhen Qu, Qiongkai Xu, Tongtong Wu, Tianyang Zhan, Gholamreza Haffari\
*<span style="color:gray">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP), Dec 2022</span>.*

+ [**Extracted BERT Model Leaks More Information than You Think!**](https://aclanthology.org/2022.emnlp-main.99/), Xuanli He, Chen Chen, Lingjuan Lyu, Qiongkai Xu\
*<span style="color:gray">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP), Dec 2022</span>.*

+ [**CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks**](https://openreview.net/forum?id=L7P3IvsoUXY), Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, Ruoxi Jia
*<span style="color:gray">Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS), Nov 2022</span>.*

+ [**Student Surpasses Teacher: Imitation Attack for Black-Box NLP APIs**](https://aclanthology.org/2022.coling-1.251/), Qiongkai Xu, Xuanli He, Lingjuan Lyu, Lizhen Qu, Gholamreza Haffari 
*<span style="color:gray">Proceedings of the 29th International Conference on Computational Linguistics (COLING), Oct 2022</span>.*

+ [**Protecting Intellectual Property of Language Generation APIs with Lexical Atermark**](https://arxiv.org/pdf/2112.02701.pdf), Xuanli He, Qiongkai Xu, Lingjuan Lyu, Fangzhao Wu, Chenguang Wang 
*<span style="color:gray">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), Feb 2022</span>.*

+ [**Personal Information Leakage Detection in Conversations**](https://www.aclweb.org/anthology/2020.emnlp-main.532.pdf), Qiongkai Xu, Lizhen Qu, Zeyu Gao, Gholamreza Haffari 
*<span style="color:gray">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Nov 2020</span>.*

+ [**Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation**](https://dl.acm.org/doi/abs/10.1145/3313831.3376315), Yolande Strengers, Lizhen Qu, Qiongkai Xu, Jarrod Knibbe 
*<span style="color:gray">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI), Apr 2020</span>.*
<!-- + [**Privacy-Aware Text Rewriting**](https://aclanthology.org/W19-8633.pdf)\
Qiongkai Xu, Lizhen Qu, Chenchen Xu, Ran Cui\
*<span style="color:gray">Proceedings of the 12th International Conference on Natural Language Generation (INLG), Oct 2019</span>.* -->

+ [**Deep Neural networks for Learning Graph Representations**](https://ojs.aaai.org/index.php/AAAI/article/download/10179/10038), Shaosheng Cao, Wei Lu, Qiongkai Xu 
*<span style="color:gray">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), Feb 2016</span>.*


+ [**GraRep: Learning Graph Representations with Global Structural Information**](https://www.researchgate.net/profile/Qiongkai-Xu/publication/301417811_GraRep/links/5847ecdb08ae8e63e633b5f2/GraRep.pdf), Shaosheng Cao, Wei Lu, Qiongkai Xu 
*<span style="color:gray">Proceedings of the 24th ACM international on conference on information and knowledge management (CIKM), Oct 2015</span>.*